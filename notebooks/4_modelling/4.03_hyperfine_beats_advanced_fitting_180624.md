---
jupytext:
  formats: ipynb,md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.14.7
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

+++ {"tags": ["remove-cell"]}

19/06/24 - basics working nicely. Didn't try fit options as yet.

Note CI est. currently seems to be an issue - running for several hours with no output. Maybe better with tighter limits set...?

UPDATE: good parts now distilled to `-redux` version of this notebook.

+++

(page:advanced-fitting)=
# Advanced fitting for hyperfine beat (stage 1 bootstrap)

For advanced fitting, try a stage 1 style bootstrap. In this case, options are:

- "basic" ignore the photoionization dynamics and just try fitting the beat to the $l=4$, ROI=0 case, since it is already pretty close and may be assumed to be directly mapped here. See {ref}`page:advanced-fitting`.
- "advanced" set (arbitrary) parameters per final state for the probe, and fit these plus the hyperfine beat model parameters. This should allow for a match to a single set of hyperfine parameters for all observables, and fulfil the stage 1 bootstrap criteria. (This page.)

---

From prior work and data:

- Forbes, R. et al. (2018) ‘Quantum-beat photoelectron-imaging spectroscopy of Xe in the VUV’, Physical Review A, 97(6), p. 063417. Available at: https://doi.org/10.1103/PhysRevA.97.063417. arXiv: http://arxiv.org/abs/1803.01081, Authorea (original HTML version): https://doi.org/10.22541/au.156045380.07795038
- Data (OSF): https://osf.io/ds8mk/
- [Quantum Metrology with Photoelectrons (Github repo)](https://github.com/phockett/Quantum-Metrology-with-Photoelectrons), particularly the [Alignment 3 notebook](https://github.com/phockett/Quantum-Metrology-with-Photoelectrons/blob/master/Alignment/Alignment-3.ipynb). Functions from this notebook have been incorporated in the current project, under `qbanalysis.hyperfine`.

+++

## Setup fitting model

Follow the modelling notebook ({ref}`page:hyperfine-beat-model`), but wrap functions for fitting.

New functions are in `qbanalysis.adv_fitting.py`.

+++

### Imports

```{code-cell} ipython3
# Load packages
# Main functions used herein from qbanalysis.hyperfine
from qbanalysis.hyperfine import *
import numpy as np
from epsproc.sphCalc import setBLMs

from pathlib import Path

dataPath = Path('/tmp/xe_analysis')
# dataTypes = ['BLMall', 'BLMerr', 'BLMerrCycle']   # Read these types, should just do dir scan here.

# # Read from HDF5/NetCDF files
# # TO FIX: this should be identical to loadFinalDataset(dataPath), but gives slightly different plots - possibly complex/real/abs confusion?
# dataDict = {}
# for item in dataTypes:
#     dataDict[item] = IO.readXarray(fileName=f'Xe_dataset_{item}.nc', filePath=dataPath.as_posix()).real
#     dataDict[item].name = item

# Read from raw data files
from qbanalysis.dataset import loadFinalDataset
dataDict = loadFinalDataset(dataPath)

# Use Pandas and load Xe local data (ODS)
# These values were detemermined from the experimental data as detailed in ref. [4].
from qbanalysis.dataset import loadXeProps
xeProps = loadXeProps()
```

## Improved model

- Add exponential state decays + error function (or masking) at t0.
- Add photoionization phenomenologically.

To test:

- trange.
- type of fit.
- adding noise.

```{code-cell} ipython3
# v2 pkg
from qbanalysis.adv_fitting import * 
```

```{code-cell} ipython3
# Create model parameters
params = initParams(xeProps)
params
```

```{code-cell} ipython3
# Compute advanced model...
calcDict = calcAdvFitModel(params, xePropsFit=xeProps, dataDict=dataDict)

calcDict.keys()
```

```{code-cell} ipython3
# xr.concat([decay, decay.sum("Isotope").expand_dims({"Isotope":['sum']})], dim="Isotope")
```

```{code-cell} ipython3
# Plot model + decay
plotHyperfineModel(calcDict['modelDA']) * plotHyperfineModel(calcDict['decay'])
```

```{code-cell} ipython3
plotHyperfineModel(calcDict['ionization'],overlay=['l'])
```

```{code-cell} ipython3
modelDS = splitUncertaintiesToDataset(calcDict['ionization'].squeeze())
modelDS

dataDS = splitUncertaintiesToDataset(dataIn.squeeze())
dataDS
```

```{code-cell} ipython3
# Calc residuals...

# Basic function
def residual(model,dataIn):
    """
    Calc least squares residual
    """
    res = (model - dataIn)**2  # Returning single value XR only in testing? Issue with dims?
                            # Ah, OK after fixing t-units
    # res = model.values - dataIn.values  # Force to NP, assumes matching size.

    return res


def residualAdv(model,dataIn, dataUn = None):
    
    model.name = 'model'
    modelDS = splitUncertaintiesToDataset(model)
    modelDS = modelDS.assign_coords({'t':modelDS['t'].values.astype(int)})  # Force coords to avoid float comparison issues.
    
    dataIn.name = 'data'
    dataDS = splitUncertaintiesToDataset(dataIn)
    dataDS = dataDS.assign_coords({'t':dataDS['t'].values.astype(int)})
    
    # Uncertainties - use data_std if present, skip if zero.
    # Use passed data if provided
    res = (dataDS['data'] - modelDS['model'])
    thres = 1e-10
    if (dataUn is None) and (dataDS['data_std'].max() < thres):
        pass
    elif dataDS['data_std'].max() > thres:
        res = res/dataDS['data_std']
    else:
        res = res/dataUn
        
    res.name = 'res'
    
    return res, dataDS, modelDS
    # return (dataDS-model) / uncertainty

# dataIn = dataDict['BLMall'].sel({'ROI':0,'l':4}).copy()
dataIn = dataDict['BLMall'].unstack().sel({'l':[2,4]}).copy()
dataUn = dataDict['BLMerr'].unstack().sel({'l':[2,4]}).copy()  # Main data has uncertainties separately currently

# if trange is not None:
#     modelIn = modelIn.sel(t=slice(trange[0],trange[1]))
#     dataIn = dataIn.sel(t=slice(trange[0],trange[1]))

# res = residual(calcDict['ionization'].squeeze(), dataIn.squeeze())
# res.name = 'residual'

# Adv version....
res, dataDS, modelDS = residualAdv(calcDict['ionization'].squeeze(), dataIn.squeeze(), dataUn = dataUn)
```

```{code-cell} ipython3
dataDS
```

```{code-cell} ipython3
# dataDS.assign_coords({'t':dataDS['t'].values.astype(int)})
```

```{code-cell} ipython3
# dataDS['data'] - modelDS['model']
```

```{code-cell} ipython3
res
```

```{code-cell} ipython3
plotHyperfineModel(res,overlay=['l'])
```

```{code-cell} ipython3
ionTest = ionizationPhenom(params.valuesdict(),decay)
plotHyperfineModel(ionTest, overlay=['l'])
```

```{code-cell} ipython3
# Test lmfit with new functions...

def calcAdvlmfit(params, trange=[0,1000], **kwargs):
    
    calcDict = calcAdvFitModel(params, xePropsFit=xeProps, dataDict=dataDict)
    
    # dataIn = dataDict['BLMall'].sel({'ROI':0,'l':4}).copy()
    # dataIn = dataDict['BLMall'].unstack().sel({'l':[2,4]}).copy()
    # dataUn = dataDict['BLMerr'].unstack().sel({'l':[2,4]}).copy()  # Main data has uncertainties separately currently

    # if trange is not None:
    #     modelIn = modelIn.sel(t=slice(trange[0],trange[1]))
    #     dataIn = dataIn.sel(t=slice(trange[0],trange[1]))

    # res = residual(calcDict['ionization'].squeeze(), dataIn.squeeze())
    # res.name = 'residual'

    res, dataDS, modelDS = residualAdv(calcDict['ionization'].squeeze(), dataIn.squeeze(), dataUn = dataUn)

    # Optionally set trange
    # NOTE: may also be set in calcBasicFitModel, so should be more careful here!
    if trange is not None:
        res = res.sel(t=slice(trange[0],trange[1]))
        # dataIn = dataIn.sel(t=slice(trange[0],trange[1]))
    
    return res.values

# Set dataIn...
dataIn = dataDict['BLMall'].unstack().sel({'l':[2,4]}).copy()
dataUn = dataDict['BLMerr'].unstack().sel({'l':[2,4]}).copy()  # Main data has uncertainties separately currently

# out = minimize(calcAdvlmfit, params, kws={'xePropsFit':xeProps, 'dataDict':dataDict})  # Working, but not passing data!
out = minimize(calcAdvlmfit, params, kws={'xePropsFit':xeProps, 'dataDict':dataDict, 'dataIn':dataIn, 'dataUn':dataUn})  # Working, but not passing data!
```

```{code-cell} ipython3
out
```

```{code-cell} ipython3
from qbanalysis.plots import plotFinalDatasetBLMt
plotOpts = {'width':800}
calcDict = calcAdvFitModel(out.params, xePropsFit=xeProps, dataDict=dataDict)
plotHyperfineModel(calcDict['ionization'],overlay=['ROI']) * plotFinalDatasetBLMt(**dataDict, **plotOpts)
```

```{code-cell} ipython3
# Check final residuals
res, dataDS, modelDS = residualAdv(calcDict['ionization'].squeeze(), dataIn.squeeze(), dataUn = dataUn)
plotHyperfineModel(res,overlay=['l'])
```

```{code-cell} ipython3
# PLOT TESTING...
from qbanalysis.plots import plotFinalDatasetBLMt
plotOpts = {'width':800}
calcDict = calcAdvFitModel(out.params, xePropsFit=xeProps, dataDict=dataDict)
# plotHyperfineModel(calcDict['ionization'],overlay=['ROI']).layout('l')

# To fix layout issues, treat l separately...
l2 = (plotFinalDatasetBLMt(**dataDict, **plotOpts) * plotHyperfineModel(calcDict['ionization'],overlay=['ROI'])).select(l=2)
l4 = (plotFinalDatasetBLMt(**dataDict, **plotOpts) * plotHyperfineModel(calcDict['ionization'],overlay=['ROI'])).select(l=4)

(l2.overlay('l').opts(title="l2") + l4.overlay('l').opts(title="l4")).cols(1)
```

```{code-cell} ipython3
calcDict['xePropsFit']
```

```{code-cell} ipython3
from qbanalysis.basic_fitting import compareResults, extractABParams
compareResults(xeProps,calcDict['xePropsFit'])
```

```{code-cell} ipython3
xePropsFit  =extractABParams(calcDict['xePropsFit'])
xePropsFit.style.set_caption("Updated results")
```

```{code-cell} ipython3
xePropsFit.droplevel(['I','F′','F'])[0:2][['A/MHz','B/MHz']]
```

![Xe table](xe_table.png)

```{code-cell} ipython3
break
```

### Testing CI

See https://lmfit.github.io/lmfit-py/confidence.html

Currently lmfit not returning std errors...?

```{code-cell} ipython3
# mini = lmfit.Minimizer(calcAdvlmfit, params, fcn_kws={'xePropsFit':xeProps, 'dataDict':dataDict})  # Working, but not passing data!
# result = minimize()

mini = lmfit.Minimizer(calcAdvlmfit, params, fcn_kws={'xePropsFit':xeProps, 'dataDict':dataDict, 'dataIn':dataIn, 'dataUn':dataUn})  
result = mini.minimize()
```

```{code-cell} ipython3
print(lmfit.fit_report(result.params))
```

```{code-cell} ipython3
ci = lmfit.conf_interval(mini, result)
lmfit.printfuncs.report_ci(ci)
```

```{code-cell} ipython3
result.params
```

```{code-cell} ipython3
# Try forcing std errors, per https://lmfit.github.io/lmfit-py/confidence.html#working-without-standard-error-estimates
for p in result.params:
    result.params[p].stderr = abs(result.params[p].value * 0.1)
```

```{code-cell} ipython3
ci = lmfit.conf_interval(mini, result)
lmfit.printfuncs.report_ci(ci)
```

### TEST FIT 1

```{code-cell} ipython3
out
```

```{code-cell} ipython3
from qbanalysis.plots import plotFinalDatasetBLMt
plotOpts = {'width':800}
calcDict = calcAdvFitModel(out.params, xePropsFit=xeProps, dataDict=dataDict)
plotHyperfineModel(calcDict['ionization'],overlay=['ROI']) * plotFinalDatasetBLMt(**dataDict, **plotOpts)
```

```{code-cell} ipython3
break
```

```{code-cell} ipython3
# Check final residuals
res, dataDS, modelDS = residualAdv(calcDict['ionization'].squeeze(), dataIn.squeeze(), dataUn = dataUn)
plotHyperfineModel(res,overlay=['l'])
```

```{code-cell} ipython3
plotFinalDatasetBLMt(**dataDict, **plotOpts)
```

```{code-cell} ipython3
# # Functions for calculation.
# # NOTE: designed for use with lmfit, expect lmfit Parameters() or params dict.

# import lmfit
# from qbanalysis.basic_fitting import calcBasicFitModel


# def calcDecays(paramDict, isoDA):
#     """
#     Apply exponential decays, exp(-t/tau), per isotope.
    
#     paramDict : dict
#         Parameters dictionary with items 'tauZ' per isotope Z.
        
#     isoDA : xr.dataarray
#         Main data structure, with dims including "Isotope" and "t".
#         Groupby & apply exponential decay per Isotope.
        
#     """
    
#     #*** Apply exponential decay (per isotope)
#     # Easier way to do this...? Here set DA per isotope, then combine and multiply.
#     # Quick test of multiply without all isotope dims also awkward, although maybe groupby would work...
    
#     # Dict + loop version
#     # decay = xr.zeros_like(isoDA)
# #     decayDict = {}
# #     for iso in [129,131]:
# #         decayDict[iso] = np.exp(-isoDA.t/paramDict[f"tau{iso}"]).expand_dims({'Isotope':[f'{iso}Xe']})
# #         # decay = decay + np.exp(-isoDA.t/paramDict[f"tau{iso}"]).expand_dims({'Isotope':[f'{iso}Xe']})
    
# #     decayDA = isoDA*stackModelToDA(decayDict)
    
#     # Groupby version - better...?
#     # Test groupby...
#     decay = isoDA.groupby("Isotope").map(lambda x: x*np.exp(-x.t/paramDict[f"tau{x.Isotope.values.item().rstrip('Xe')}"]))
#     decay.name = 'decay'
    
#     return decay

# def ionizationPhenom(paramDict,modelDA):
#     """
#     Basic amplitude/phase + offset ionization channel model.

#     """
    
#     # Assume isotope independent...?
#     # Also ignore total XS here
#     modelIn = modelDA.sum("Isotope").sel({'K':2})
    
#     # ROI only version - assume isotope independent params
#     modelOutComponents = []
#     for ROI in [0,1]:
#         lparams = [2,4]
#         paramsAmp = [paramDict[f"l{l}_amp_{ROI}"] for l in lparams]
#         paramsOffset = [paramDict[f"l{l}_offset_{ROI}"] for l in lparams]
        
#         modelOutComponents.append((modelIn * xr.DataArray(paramsAmp,coords=[("l",lparams)]) + xr.DataArray(paramsOffset,coords=[("l",lparams)])).expand_dims({"ROI":[ROI]}))
        
#         # for item in ['amp','offset']:
#         #     [params.add(f"l{l}_{item}_{ROI}", value=1.0) for l in [2,4]]
    
#     modelOut = xr.concat(modelOutComponents,dim="ROI")
#     modelOut.name = "Ionization test"
    
#     # K2t = decay.sel({'K':2,'Isotope':'129Xe'}).squeeze()
#     # K2t = K2t * xr.DataArray([20,-10],coords=[("l",[0,2])]) + xr.DataArray([1,-1],coords=[("l",[0,2])])
#     # K2t.name = "Ionization test"

#     return modelOut
                                           

# def calcAdvFitModel(params, **kwargs):
#     """
#     Wrap basic fit model, and add some features.
    
#     Note passed params expect lmfit Parameters() object, or dictionary.
    
#     """
    
#     if isinstance(params, lmfit.parameter.Parameters):
#         paramDict = params.valuesdict()
#     else:
#         paramDict = params
    
#     #*** Run basic case as base
#     # TODO: return modelDA here too
#     # TODO: arg passing
#     # xDataBasic = xData[0:4]  # For basic case only use first 4 (splitting) params
#     # xDataBasic = [paramDict[k] for k,v in paramDict.items() if k.startswith('s')]  # For dict case, use s0...3
#     xDataBasic = [paramDict[f"s{n}"] for n in range(0,4)]  # Assume number of params and enforce ordering. 
#     calcBasicDict = calcBasicFitModel(xDataBasic, fitFlag=False, returnType='full', **kwargs)
    
#     # Use original model results and apply additional params
#     # modelDA = stackModelToDA(calcDict['modelDict'])  # Use original model?
#     isoDA = calcBasicDict['modelDA'].sel({'Isotope':['129Xe','131Xe']})  # Use isotope-weighted results
    
    
#     #*** Apply exponential decay (per isotope)
#     # Easier way to do this...? Here set DA per isotope, then combine and multiply.
#     # Quick test of multiply without all isotope dims also awkward, although maybe groupby would work...
    
#     # Dict + loop version
#     # decay = xr.zeros_like(isoDA)
# #     decayDict = {}
# #     for iso in [129,131]:
# #         decayDict[iso] = np.exp(-isoDA.t/paramDict[f"tau{iso}"]).expand_dims({'Isotope':[f'{iso}Xe']})
# #         # decay = decay + np.exp(-isoDA.t/paramDict[f"tau{iso}"]).expand_dims({'Isotope':[f'{iso}Xe']})
    
# #     decayDA = isoDA*stackModelToDA(decayDict)
    
#     # Groupby version - better...?
#     # Test groupby...
#     # decay = isoDA.groupby("Isotope").map(lambda x: x*np.exp(-x.t/paramDict[f"tau{x.Isotope.values.item().rstrip('Xe')}"]))
#     # decay.name = 'decay'
    
#     decay = calcDecays(paramDict, isoDA)

#     #*** Apply ionization model
#     # 
    
#     return calcBasicDict, decay
    
```

```{code-cell} ipython3
plotOpts = {'width':800}
fitParamsCol = 'Splitting/cm−1'
xePropsFit = xeProps.copy()
x0 = unumpy.nominal_values(xePropsFit[fitParamsCol].to_numpy())

# calcDict = calcAdvFitModel(x0, xePropsFit=xePropsFit, dataDict=dataDict)
calcDict, decay = calcAdvFitModel(params, xePropsFit=xePropsFit, dataDict=dataDict)
```

```{code-cell} ipython3
calcDict.keys()
```

```{code-cell} ipython3
decay
```

```{code-cell} ipython3
# Ionization... just want amplitude + offset per channel...?

# decay.sel({'K':2}).groupby('Isotope').apply(

# Test single channel... OK
K2t = decay.sel({'K':2,'Isotope':'129Xe'}).squeeze()
K2t = K2t * xr.DataArray([20,-10],coords=[("l",[0,2])]) + xr.DataArray([1,-1],coords=[("l",[0,2])])
K2t.name = "Ionization test"

dataPlot = K2t
overlay = 'l'

DS = splitUncertaintiesToDataset(dataPlot)
hvDS = hvPlotters.hv.Dataset(DS.unstack())
hvDS.to(hvPlotters.hv.Curve, kdims = ['t']).overlay(overlay)
# plotHyperfineModel(K2t, plotSpread=False, overlay=['l'])  # NOTE - now debugged!
```

```{code-cell} ipython3
plotHyperfineModel(isoDA) * plotHyperfineModel(decay.sum('Isotope'))
```

```{code-cell} ipython3
ionTest = ionizationPhenom(params.valuesdict(),decay)
plotHyperfineModel(ionTest, overlay=['l'])
```

```{code-cell} ipython3
ionTest
```

```{code-cell} ipython3
decay
```

```{code-cell} ipython3
ionizationPhenom(params.valuesdict(),decay)
```

```{code-cell} ipython3
isoDA = calcDict['modelDA'].sel({'Isotope':['129Xe','131Xe']})
```

```{code-cell} ipython3
isoDA
```

```{code-cell} ipython3
decay = xr.ones_like(isoDA)

dTemp = {}

for iso in [129,131]:
    # # decay = decay.sel({"Isotope":f"{iso}Xe"}, drop=False) * np.exp(-isoDA.t/paramDict[f"tau{iso}"])

    dTemp[iso] = np.exp(-isoDA.t/paramDict[f"tau{iso}"]).expand_dims({'Isotope':[f'{iso}Xe']})
    
    

# decay.where(
# decay = decay*dTemp

# decay.sel({"Isotope":"129Xe"}) * dTemp + decay.sel({"Isotope":"131Xe"})
# decay


decayStack = stackModelToDA(dTemp)

isoDA*decayStack
```

```{code-cell} ipython3
isoDA.Isotope.values.item()  #.rstrip('Xe')
```

```{code-cell} ipython3
# Test groupby...
isoDA.groupby("Isotope").map(lambda x: np.exp(-x.t/paramDict[f"tau{x.Isotope.values.item().rstrip('Xe')}"]))
# isoDA.groupby("Isotope").map(lambda x: print(x.Isotope.values.item().rstrip('Xe')))
```

```{code-cell} ipython3
from scipy.special import erf  # Error function if required, or use as mask?

tau=500
# decay = erf(isoDA.t)*np.exp(-isoDA.t/tau).expand_dims({'Isotope':['129Xe']})  # Just add isotope dim to allow * by main data?
decay = np.exp(-isoDA.t/tau).expand_dims({'Isotope':['129Xe']})  # Just add isotope dim to allow * by main data?
```

```{code-cell} ipython3
# Basics OK.
# TODO: should multiply only K=0 and renorm?
# TODO: remove t<=0 terms.
testMult = isoDA * decay

testMult.values = unumpy.nominal_values(testMult)

# xr.where(testMult.t>0, unumpy.nominal_values(testMult),0)

testMult.squeeze().unstack().hvplot.line(x='t')
```

```{code-cell} ipython3
erf(isoDA.t)
```

## Fitting with lmfit

- Easy parameter control.
- Propagate uncertainties.

See https://lmfit.github.io/lmfit-py/intro.html

```{code-cell} ipython3
xeProps
```

```{code-cell} ipython3
# def pdIndexMap(df):
#     """
#     Convert list of tuple labels to short str format from PD dataframe.
    
#     Also append short names as column in df.
    
#     Useful for setting up mappings to fitting params for lmfit.
#     """
    
#     indList = df.index
    
#     # Parameter names for lmfit [a-z_][a-z0-9_]*, so replace '.' and '-' signs.
#     nameList = ['_'.join(str(ele).replace('-','n').replace('.','') for ele in sub) for sub in indList]
    
#     # shortNameList = [list(f"{str(ele)}_s{n}" for ele in sub) for n,sub in enumerate(indList)]
#     # shortNameList = [f"I{str(sub[0])}_s{n}" for n,sub in enumerate(indList)]
#     shortNameList = [f"s{n}" for n,sub in enumerate(indList)]
    
#     # Generate map {full names : lables}
#     indMapLong = dict(zip(indList, nameList))
#     indMapShort = dict(zip(indList, shortNameList))
    
#     # Append to original table
#     df['label']=shortNameList
    
#     return locals()


# def pdParamsReplaceFromMap(df, pdMap, params, dataCol = 'Splitting/cm−1'):
#     """
#     Convert lmfit.params items back to original PD dataframe via labels.
#     """

#     dfOut = df.copy()

#     for k,v in pdMap['indMapShort'].items():
#         # Replace by keys
#         # xeTest.loc[k][dataCol] = xeTest.loc[k][dataCol]*n

#         # Replace by value (short name) lookup
#         # This should ensure consistency in replacement ordering etc.
#         dfOut.loc[dfOut['label']==v,dataCol] = params.valuesdict()[v]
        
#         # print(params.valuesdict()[v])


#     return dfOut
```

```{code-cell} ipython3
pdMap = pdIndexMap(xeProps)
# xeProps['lmfit']=pdMap['shortNameList']
xeProps
# pdMap
```

```{code-cell} ipython3
# Create parameters for the fit
# v2 better
# from lmfit import minimize, Parameters

# def initParams(xeProps):
#     """
#     Init lmfit Parameters() for Xe advanced hyperfine model
    
#     """
    
#     # Set labels for params
#     pdMap = pdIndexMap(xeProps)

#     # Setup parameters from df
#     params = Parameters()

#     # Iterate over PD rows and assign to params.
#     # May be neater way to do this...?
#     for item in xeProps.iterrows():
#         itemVal = unumpy.nominal_values(item[1]['Splitting/cm−1'])
#         params.add(item[1]['label'], value = itemVal, min = 0, max = 1)

#     #*** Add additional params as required for the advanced model...
#     # Lifetimes
#     params.add("tau129", value = 500)
#     params.add("tau131", value = 500)

#     # Ionization model params - just set amplitude + offset for l=2,4 modelling
#     # Will also need ROI (channel) here too...? Or just apply these to sum, if assumed iso independent
#     # for iso in [129,131]:
#     #     for item in ['amp','offset']:
#     #         [params.add(f"l{l}_{item}_{iso}", value=1.0) for l in [2,4]]

#     # ROI only version - assume isotope independent params
#     for ROI in [0,1]:
#         for item in ['amp','offset']:
#             [params.add(f"l{l}_{item}_{ROI}", value=np.random.uniform(-1,1)) for l in [2,4]]

#     return params

params = initParams(xeProps)
params
```

```{code-cell} ipython3
dataDict
```

```{code-cell} ipython3
type(params)  #['s0']   #.valuesdict()['s0']
```

```{code-cell} ipython3
# Test param remapper
pdParamsReplaceFromMap(xeProps,pdMap, params)
```

```{code-cell} ipython3
params.valuesdict()
```

```{code-cell} ipython3
# Check unpacking - ordering OK...?
paramDict = params.valuesdict()
[paramDict[k] for k,v in paramDict.items() if k.startswith('s')] 
```

```{code-cell} ipython3
# Enforce...
[paramDict[f"s{n}"] for n in range(0,4)] 
```

```{code-cell} ipython3
dataCol = 'Splitting/cm−1'
# [xeProps.loc[k][dataCol]*2 for k,v in pdMap['indMapShort'].items()]

xeTest = xeProps.copy()
n=1
for k,v in pdMap['indMapShort'].items():
    # Replace by keys
    # xeTest.loc[k][dataCol] = xeTest.loc[k][dataCol]*n
    
    # Replace by value (short name) lookup
    # This should ensure consistency in replacement
    xeTest.loc[xeTest['label']==v,dataCol] = params.valuesdict()[v]
    
    n = n+5
    
xeTest
    

```

```{code-cell} ipython3
xeProps
```

```{code-cell} ipython3
# Create parameters for the fit
# v1 testing
from lmfit import minimize, Parameters

params = Parameters()

# Iterate over PD rows and assign to params.
# May be neater way to do this...?
for item in xeProps.iterrows():
    # print(item)
    
    # Name from index - this 
    # itemInds = ''.join((str(value) for value in item[0]))
    itemInds = [''.join(str(value)) for value in item[0]]
    itemName = '_'.join(itemInds).replace('.','')  # Set param name from indexes
                                                   # Note "[a-z_][a-z0-9_]*" and valid python var name.
    
    # print(itemName)
    # print(type(itemName))
    # print((''.join(str(value)) for value in item[0]))
    # list(item[0]).join('')
    # params.add(f"Splitting_{itemName}", value = item[-1][0], min = 0, max = 1)
    
    # OK up to itemName[0:5]
    # params.add(f"s_{itemName[0:5]}", value = item[-1][0], min = 0, max = 1)
    # params.add(f"s{itemName[0:7]}", value = item[-1][0], min = 0, max = 1)
    
    # print(item[-1])  #['Splitting/cm−1'])
    itemVal = unumpy.nominal_values(item[-1]['Splitting/cm−1'])
    params.add(f"s_{itemName}", value = itemVal, min = 0, max = 1)

# params.add('amp', value=10, vary=False)
# params.add('decay', value=0.007, min=0.0)
# params.add('phase', value=0.2)
# params.add('frequency', value=3.0, max=10)
                            
params

# TODO: easy/neat way to index these back to original case... see PEMtk....
# UPDATE: main difference there is piece-wise list/dict creation prior to setting params, but quite similar.
```

```{code-cell} ipython3
# Map items to names
xeProps.index.to_list()
```

```{code-cell} ipython3
params.keys()
```

```{code-cell} ipython3
params.valuesdict()
```

```{code-cell} ipython3
def testLocals(**kwargs):
    
    z=2
    
    return locals()

testLocals(x=5)
```

## lmfit reboot/test

From https://lmfit.github.io/lmfit-py/intro.html

```{code-cell} ipython3
from numpy import linspace, random
from scipy.optimize import leastsq

# generate synthetic data with noise
x = linspace(0, 100)
noise = random.normal(size=x.size, scale=0.2)
data = 7.5 * sin(x*0.22 + 2.5) * exp(-x*x*0.01) + noise

# generate experimental uncertainties
uncertainty = abs(0.16 + random.normal(size=x.size, scale=0.05))
```

```{code-cell} ipython3
from numpy import exp, sin

from lmfit import minimize, Parameters


def residual(params, x, data, uncertainty):
    amp = params['amp']
    phaseshift = params['phase']
    freq = params['frequency']
    decay = params['decay']

    model = amp * sin(x*freq + phaseshift) * exp(-x*x*decay)

    return (data-model) / uncertainty


params = Parameters()
params.add('amp', value=10)
params.add('decay', value=0.007)
params.add('phase', value=0.2)
params.add('frequency', value=3.0)

out = minimize(residual, params, args=(x, data, uncertainty))
```

```{code-cell} ipython3
out
```

## Test some PEMtk methods...

```{code-cell} ipython3
from pemtk.fit._util import lmmuListStrReformat

lmmuListStrReformat(xeProps.index)
```

```{code-cell} ipython3

```
